process.shell = ['/bin/bash']

profiles {

    // TODO: add conda

    docker {
        docker.enabled         = true
        docker.userEmulation   = true
        fixOwnership           = true
        runOptions             = "-u \$(id -u):\$(id -g)"
        singularity.enabled    = false
        shifter.enabled        = false
        registry               = "snads"
    }

    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
        shifter.enabled        = false
        conda.enabled          = false
        params.enable_conda    = false
    }

    sge {
        process {
            executor = 'sge'
            penv     = 'smp'
            queue    = 'all.q'
        }
    }

}

def trace_timestamp = new java.util.Date().format('yyyy-MM-dd HH:mm:ss')

// Global default params
params {

    // Analysis options
    exclude = 'none'
    targetChunkSize = false
    targetNChunks = false
    backgrChunkSize = false
    backgrNChunks = false
    max_bg_bind_rate = 0.00000667
    min_fg_bind_rate = 0.00001
    min_bg_bind_dist = 30000
    max_fg_bind_dist = 36000
    set_find_workers = 1
    max_sets_search = -1
    min_kmer_size = 5
    max_kmer_size = 12
    min_tm = 15
    max_tm = 45
    find_sets_min_size = 2
    find_sets_max_size = 7
    max_dimer_bp = 3

    // Boilerplate options
    outpath = new File("${launchDir}").getCanonicalPath()
    logpath = new File("${outpath}/.log").getCanonicalPath()
    n_top_primers = 200
    n_top_sets = -1
    run_find_sets = true
    help = false
    version = false

    // Max resource options
    // Defaults only, expecting to be overwritten
    max_memory                 = '128.GB'
    max_cpus                   = 16
    max_time                   = '240.h'
}

timeline {
    enabled = true
    file    = "${params.outpath}/timeline.${trace_timestamp}.html"
}

report {
    enabled = true
    file    = "${params.outpath}/report.${trace_timestamp}.html"
}

trace {
    enabled = true
    fields  = 'task_id,name,status,exit,realtime,%cpu,%mem,rss,vmem,peak_rss,peak_vmem,rchar,wchar'
    file    = "${params.outpath}/trace.${trace_timestamp}.txt"
}

dag {
    enabled = true
    file    = "${params.outpath}/pipeline_dag.${trace_timestamp}.svg"
}

manifest {
    author = 'Sarah Nadeau'
    description = 'Generate candidate primer set for selective whole-genome amplification'
    mainScript = 'main.nf'
    nextflowVersion = '>=20.01.0'
    version = '1.0.0'
}

// Function to ensure that resource requirements don't go beyond a maximum limit
// This code is from: https://github.com/nf-core/rnaseq/blob/3643a94411b65f42bce5357c5015603099556ad9/nextflow.config
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
